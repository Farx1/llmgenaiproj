"""Retrieval agent for RAG queries."""
try:
    from langchain.agents import create_agent
except ImportError:
    try:
        from langchain.agents import create_tool_calling_agent
        create_agent = None
    except ImportError:
        create_agent = None
        create_tool_calling_agent = None

from langchain.tools import tool
try:
    from langchain_core.prompts import ChatPromptTemplate
except ImportError:
    from langchain.prompts import ChatPromptTemplate
from typing import Dict, Any
from utils.llm_factory import get_llm
from rag.vector_store import vector_store


class RetrievalAgent:
    """Agent specialized in retrieval-augmented generation."""
    
    def __init__(self, model_name: str = None):
        """
        Initialize the retrieval agent.
        
        Args:
            model_name: Name of the model to use
        """
        self.llm = get_llm(model_name=model_name)
        self.vector_store = vector_store
        self.tool = self._create_retrieval_tool()
        
        # Use SimpleAgent by default as it works with all LLMs including Ollama
        self.agent = self._create_simple_agent()
    
    def _create_retrieval_tool(self):
        """Create the retrieval tool."""
        vector_store_ref = self.vector_store
        
        @tool
        def search_documentation(query: str) -> str:
            """Recherche la documentation ESILV pour des informations sur les programmes, admissions, cours et politiques.
            
            Args:
                query: La requête de recherche sur les programmes ESILV, admissions, cours, etc.
            
            Returns:
                Extraits de documentation pertinents avec citations [source:file#chunk]
            """
            import os
            import logging
            logger = logging.getLogger(__name__)
            
            try:
                # Try to search directly - don't rely on get_collection_info() which may timeout
                # The similarity_search will handle empty collections gracefully
                logger.info(f"DEBUG: Searching RAG for query: {query[:100]}")
                logger.info(f"DEBUG: Attempting hybrid search (vector + keyword)...")
                
                # Hybrid search: combine vector similarity with keyword search in metadata
                # First, try vector similarity search
                # Use dynamic k based on query type - more docs for better context
                query_lower = query.lower()
                
                # Check if user wants detailed answer
                wants_details = any(word in query_lower for word in [
                    "détails", "détail", "explique", "expliquer", "développe", "développer",
                    "plus d'infos", "plus d'informations", "en détail", "en profondeur",
                    "complètement", "complet", "tout", "tous", "liste", "lister"
                ])
                
                # Optimized k for better context without overwhelming the model
                # Keep k reasonable to avoid token limit issues (Llama3 has ~8k token limit)
                if any(word in query_lower for word in ["majeure", "majeures", "major", "majors", "spécialisation", "spécialisations"]):
                    k_value = 8  # Reduced from 20 - enough for comprehensive list
                elif any(word in query_lower for word in ["parcours", "quantique", "quantum", "programme", "formation"]):
                    k_value = 6  # Reduced from 18 - enough for detailed answer
                else:
                    k_value = 5  # Reduced from 15 - enough for general queries
                
                docs = vector_store_ref.similarity_search(query, k=k_value)
                logger.info(f"DEBUG: ✅ Vector search returned {len(docs)} documents (k={k_value})")
                
                # Log first few results to verify they're relevant
                if docs:
                    logger.info(f"DEBUG: First result preview: {docs[0].page_content[:200] if hasattr(docs[0], 'page_content') else str(docs[0])[:200]}")
                    logger.info(f"DEBUG: First result metadata: {docs[0].metadata if hasattr(docs[0], 'metadata') else 'No metadata'}")
                
                # Rerank and filter results to prioritize relevant documents
                # Score documents based on keyword matches in title/url
                query_lower = query.lower()
                query_keywords = [w for w in query_lower.split() if len(w) > 2]
                
                # Score each document based on relevance
                scored_docs = []
                for doc in docs:
                    score = 0
                    metadata = getattr(doc, 'metadata', {}) if hasattr(doc, 'metadata') else {}
                    if isinstance(doc, dict):
                        metadata = doc.get('metadata', {})
                    
                    title = str(metadata.get("title", "")).lower()
                    url = str(metadata.get("url", metadata.get("source", ""))).lower()
                    content = doc.page_content.lower() if hasattr(doc, 'page_content') else str(doc).lower()
                    
                    # High score for exact matches in title/url
                    for keyword in query_keywords:
                        if keyword in title:
                            score += 10  # High priority for title matches
                        if keyword in url:
                            score += 8   # High priority for URL matches
                        if keyword in content[:200]:  # First 200 chars
                            score += 3
                    
                    # Extra boost for important terms
                    important_terms = ["quantique", "quantum", "parcours", "majeure"]
                    for term in important_terms:
                        if term in query_lower:
                            if term in title or term in url:
                                score += 15  # Very high priority
                    
                    scored_docs.append((score, doc))
                
                # Sort by score (highest first) and take top results
                scored_docs.sort(key=lambda x: x[0], reverse=True)
                docs = [doc for score, doc in scored_docs]
                
                # Limit to top results after reranking (prioritize highest scores)
                # Take top 6-8 documents max to avoid overwhelming the model
                max_docs = 6 if wants_details else 4  # 4 for brief, 6 for detailed
                docs = docs[:max_docs]
                
                logger.info(f"DEBUG: ✅ After reranking: {len(docs)} documents (top {max_docs} by relevance)")
                if docs:
                    top_metadata = getattr(docs[0], 'metadata', {}) if hasattr(docs[0], 'metadata') else {}
                    if isinstance(docs[0], dict):
                        top_metadata = docs[0].get('metadata', {})
                    logger.info(f"DEBUG: Top result after reranking: {top_metadata.get('title', 'N/A')}")
                
                # Skip collection info check during streaming - it's too slow
                # Only log that we have search results
                logger.info(f"DEBUG: ✅ Found {len(docs)} relevant documents from RAG search")
                
                if not docs or len(docs) == 0:
                    logger.warning("DEBUG: ⚠️ No documents found in similarity_search - collection may be empty or query not relevant")
                    # Try to verify if collection is actually empty
                    try:
                        collection = vector_store_ref.client.get_collection(name=vector_store_ref.collection_name)
                        sample = collection.get(limit=1)
                        if sample and "ids" in sample and len(sample["ids"]) > 0:
                            logger.info("DEBUG: Collection has documents but similarity_search returned nothing - query may not be relevant")
                            return "Aucune documentation pertinente trouvée dans la base de connaissances pour cette requête. Vous pouvez utiliser vos connaissances générales pour répondre à la question."
                        else:
                            logger.warning("DEBUG: Collection appears to be empty")
                            return "Aucune documentation trouvée dans la base de connaissances. La collection est vide. Veuillez indexer des documents d'abord en utilisant le scraping (backend/scrape_esilv.py) ou l'upload de documents via l'interface web."
                    except Exception as verify_error:
                        logger.error(f"DEBUG: Error verifying collection: {verify_error}")
                        return "Aucune documentation pertinente trouvée dans la base de connaissances. Vous pouvez utiliser vos connaissances générales pour répondre à la question."
                
                if not docs or len(docs) == 0:
                    logger.info("No relevant documentation found for query.")
                    return "Aucune documentation pertinente trouvée dans la base de connaissances. Vous pouvez utiliser vos connaissances générales pour répondre à la question."
                
                # Build context blocks with citations (as shown in the notebook)
                context_blocks = []
                for idx, doc in enumerate(docs):
                    try:
                        # Extract content
                        if hasattr(doc, 'page_content'):
                            content = doc.page_content
                        elif hasattr(doc, 'content'):
                            content = doc.content
                        elif isinstance(doc, dict):
                            content = doc.get('page_content', doc.get('content', str(doc)))
                        else:
                            content = str(doc)
                        
                        if not content:
                            continue
                        
                        # Extract source for citation
                        metadata = getattr(doc, 'metadata', {}) if hasattr(doc, 'metadata') else {}
                        if isinstance(doc, dict) and 'metadata' not in dir(doc):
                            metadata = doc.get('metadata', {})
                        
                        source = metadata.get("source", metadata.get("url", metadata.get("filename", "unknown")))
                        base = os.path.basename(str(source)) if source else "unknown"
                        citation = f"[source:{base}#chunk{idx}]"
                        
                        # Extract images from metadata (may be JSON string or list)
                        images_raw = metadata.get("images", [])
                        images = []
                        if images_raw:
                            if isinstance(images_raw, str):
                                # Decode JSON string
                                try:
                                    import json
                                    images = json.loads(images_raw) if images_raw else []
                                except (json.JSONDecodeError, TypeError):
                                    images = []
                            elif isinstance(images_raw, list):
                                images = images_raw
                        
                        images_info = ""
                        if images:
                            images_list = []
                            for img_url in images[:5]:  # Limit to 5 images per chunk
                                if isinstance(img_url, str) and img_url.startswith('http'):
                                    # Format as clickable markdown image link: [![alt](img_url)](img_url)
                                    images_list.append(f"[![Image]({img_url})]({img_url})")
                            if images_list:
                                images_info = "\n\n**Images associées:**\n" + "\n".join(images_list)
                        
                        # Extract additional metadata for better structure
                        title = metadata.get("title", base)
                        url = metadata.get("url", metadata.get("source", "N/A"))
                        chunk_index = metadata.get("chunk_index", idx)
                        total_chunks = metadata.get("total_chunks", "?")
                        content_type = metadata.get("content_type", "document")
                        file_type = metadata.get("file_type", "unknown")
                        
                        # Compact format - truncate content to avoid token limit
                        # Limit each chunk to 600 chars (enough for essential info, prevents overflow)
                        if content and len(content.strip()) > 20:
                            # Truncate content to essential info
                            content_truncated = content.strip()
                            if len(content_truncated) > 600:
                                # Try to truncate at sentence boundary
                                sentences = content_truncated[:600].rsplit('.', 1)
                                if len(sentences) > 1:
                                    content_truncated = sentences[0] + '.'
                                else:
                                    content_truncated = content_truncated[:600] + '...'
                            
                            # Compact format: title and essential content only
                            block = f"""[{title[:60]}]
{content_truncated}
"""
                            context_blocks.append(block.strip())
                    except Exception as doc_error:
                        logger.warning(f"Error processing document {idx}: {str(doc_error)}")
                        continue
                
                if not context_blocks:
                    return "Aucune documentation pertinente trouvée dans la base de connaissances. Vous pouvez utiliser vos connaissances générales pour répondre à la question."
                
                # Simple join - no fancy headers to save tokens
                # Hard limit: truncate context to 8000 chars max to avoid token limit
                formatted_context = "\n\n".join(context_blocks)
                
                # Truncate if too long (Llama3 has ~8k token limit)
                if len(formatted_context) > 8000:
                    logger.warning(f"DEBUG: Context too long ({len(formatted_context)} chars), truncating to 8000")
                    truncated = formatted_context[:8000]
                    last_block_end = truncated.rfind('\n\n[', 0, 8000)
                    if last_block_end > 6000:
                        formatted_context = truncated[:last_block_end]
                    else:
                        formatted_context = truncated
                
                logger.info(f"DEBUG: ✅ Formatted context length: {len(formatted_context)}")
                logger.info(f"DEBUG: ✅ Context preview (first 500 chars): {formatted_context[:500]}")
                
                return formatted_context
║          {count} document(s) pertinent(s) trouvé(s)        ║
╚═══════════════════════════════════════════════════════════╝

""".format(count=len(context_blocks))
                
                context_footer = """

╔═══════════════════════════════════════════════════════════╗
║              FIN DE LA DOCUMENTATION ESILV                ║
╚═══════════════════════════════════════════════════════════╝"""
                
                # Join blocks with clear separation
                formatted_context = context_header + "\n\n".join(context_blocks) + context_footer
                return formatted_context
            except Exception as e:
                import traceback
                logger.error(f"Error in search_documentation: {str(e)}")
                logger.error(f"Traceback: {traceback.format_exc()}")
                return "Aucune documentation pertinente trouvée dans la base de connaissances. Vous pouvez utiliser vos connaissances générales pour répondre à la question."
        
        return search_documentation
    
    def _get_system_prompt(self) -> str:
        """Get the system prompt for the retrieval agent."""
        return """Tu es un assistant spécialisé pour l'école d'ingénieurs ESILV. Ton rôle est de répondre aux questions sur:
- Les programmes academiques et specialisations (majeures)
- Les conditions d'admission et processus
- Les descriptions de cours et curriculum
- Les politiques et procedures de l'ecole
- Les informations generales sur ESILV

Utilise l'outil search_documentation pour trouver des informations pertinentes dans la documentation vectorisee. Si aucune documentation n'est trouvee, utilise tes connaissances generales pour repondre de maniere utile et precise. Reponds toujours en francais de maniere claire et professionnelle."""
    
    def _create_simple_agent(self):
        """Create a simple agent when create_agent is not available."""
        tool_ref = self.tool
        llm_ref = self.llm
        system_prompt = self._get_system_prompt()
        
        class SimpleAgent:
            async def ainvoke(self, input_dict):
                """Invoke the agent."""
                import logging
                logger = logging.getLogger(__name__)
                
                # Support both {"input": "..."} and {"messages": [...]} formats
                if "input" in input_dict:
                    user_message = input_dict["input"]
                else:
                    messages = input_dict.get("messages", [])
                    if not messages:
                        return {"output": ""}
                    user_message = messages[-1].get("content", "") if isinstance(messages[-1], dict) else str(messages[-1])
                
                logger.info(f"Retrieval agent processing query: {user_message[:50]}...")
                
                # Use the tool directly
                try:
                    logger.info("DEBUG: ========== RETRIEVAL AGENT TOOL CALL ==========")
                    logger.info(f"DEBUG: Calling retrieval tool with query: {user_message}")
                    tool_result = tool_ref.invoke(user_message) if hasattr(tool_ref, 'invoke') else tool_ref(user_message)
                    logger.info(f"DEBUG: ✅ Tool result received (length: {len(str(tool_result))})")
                    logger.info(f"DEBUG: Tool result preview (first 500 chars): {str(tool_result)[:500]}")
                    logger.info("DEBUG: ==============================================")
                    
                    # Build RAG prompt with context (as shown in the notebook)
                    from langchain_core.messages import HumanMessage
                    
                    # Build prompt following LangChain RAG best practices - simple and clear
                    if tool_result and "Aucune documentation" not in tool_result and "collection est vide" not in tool_result:
                        # Check if user wants detailed answer
                        query_lower = user_message.lower()
                        wants_details = any(word in query_lower for word in [
                            "détails", "détail", "explique", "expliquer", "développe", "développer",
                            "plus d'infos", "plus d'informations", "en détail", "en profondeur",
                            "complètement", "complet", "tout", "tous", "liste", "lister"
                        ])
                        
                        # Context found - use ULTRA STRICT RAG prompt with brevity instruction
                        detail_instruction = "Réponds de manière DÉTAILLÉE et COMPLÈTE en utilisant toutes les informations pertinentes du contexte." if wants_details else "Réponds de manière BRÈVE et CONCISE. Donne seulement l'essentiel (2-3 phrases maximum). Si l'utilisateur veut plus de détails, il le demandera explicitement."
                        
                        prompt = f"""Tu es un assistant expert EXCLUSIVEMENT pour l'école d'ingénieurs ESILV.

⚠️⚠️⚠️ RÈGLE CRITIQUE - À RESPECTER IMPÉRATIVEMENT ⚠️⚠️⚠️

Tu DOIS répondre UNIQUEMENT en utilisant les informations du contexte ci-dessous.
INTERDICTION TOTALE d'utiliser tes connaissances générales, les questions sont posées sur l'ESILV et ce qui est relié à l'ESILV.
Si tu utilises des informations qui ne sont PAS dans le contexte, ta réponse sera INCORRECTE.

CONTEXTE DE LA DOCUMENTATION ESILV (utilise UNIQUEMENT ces informations):
{tool_result}

QUESTION DE L'UTILISATEUR: {user_message}

INSTRUCTIONS STRICTES:
1. Lis attentivement le contexte ci-dessus
2. Trouve les informations pertinentes dans le contexte pour répondre à la question
3. Réponds UNIQUEMENT en utilisant ces informations du contexte
4. {detail_instruction}
5. Si l'information n'est pas dans le contexte, dis: "Je ne trouve pas cette information dans la documentation ESILV indexée."
6. Réponds en français
7. ❌ INTERDICTION ABSOLUE de répéter des mots/phrases. Si tu commences à répéter, ARRÊTE immédiatement.
8. Ne répète JAMAIS les phrases ou les mots - chaque mot ne doit apparaître qu'une seule fois
9. Structure ta réponse clairement

COMMENCE TA RÉPONSE MAINTENANT (utilise UNIQUEMENT le contexte ci-dessus):"""
                    else:
                        # No context found or collection is empty
                        if "collection est vide" in tool_result:
                            # Collection is empty - tell user to index documents
                            prompt = f"""{system_prompt}

Question: {user_message}

⚠️ IMPORTANT: La base de connaissances est vide. Aucune documentation n'a été indexée.

Réponds à la question en utilisant tes connaissances générales, mais informe l'utilisateur que pour des informations précises et à jour, il doit d'abord indexer la documentation ESILV en utilisant le scraping (backend/scrape_esilv.py) ou l'upload de documents via l'interface web.

Réponse:"""
                        else:
                            # No relevant context found - use general knowledge but be clear
                            prompt = f"""{system_prompt}

Question: {user_message}

Aucune documentation pertinente n'a été trouvée dans la base de connaissances pour cette question spécifique. 

Réponds en utilisant tes connaissances générales, mais sois clair que ces informations peuvent ne pas être à jour ou spécifiques à ESILV. Recommande à l'utilisateur de consulter le site web officiel de l'ESILV pour des informations précises.

Réponse:"""
                    
                    prompt_messages = [HumanMessage(content=prompt)]
                    
                    # Log to verify context is being passed
                    logger.info(f"DEBUG: Context length: {len(tool_result) if tool_result else 0}")
                    logger.info(f"DEBUG: Context preview (first 500 chars): {tool_result[:500] if tool_result else 'None'}")
                    logger.info(f"DEBUG: Sending prompt to LLM (length: {len(prompt)})")
                    
                    logger.info("Calling LLM to format response...")
                    if hasattr(llm_ref, 'ainvoke'):
                        llm_response = await llm_ref.ainvoke(prompt_messages)
                    else:
                        llm_response = llm_ref.invoke(prompt_messages) if hasattr(llm_ref, 'invoke') else str(llm_ref)
                    
                    answer = llm_response.content if hasattr(llm_response, 'content') else str(llm_response)
                    logger.info(f"DEBUG: Received answer length: {len(answer)}")
                    logger.info(f"DEBUG: Answer preview (first 200 chars): {answer[:200]}")
                    
                    logger.info("LLM response received")
                    
                    # Extract content properly - handle different response formats
                    answer = ""
                    if hasattr(llm_response, 'content'):
                        answer = llm_response.content
                    elif isinstance(llm_response, str):
                        answer = llm_response
                    elif hasattr(llm_response, 'text'):
                        answer = llm_response.text
                    else:
                        # Try to extract from dict or other formats
                        answer = str(llm_response)
                        # Remove metadata if present (like role='assistant', thinking=None, etc.)
                        import re
                        # If answer contains metadata format, extract just the content
                        content_match = re.search(r"content=['\"](.*?)['\"]", answer, re.DOTALL)
                        if content_match:
                            answer = content_match.group(1)
                        # Clean up any remaining metadata patterns
                        answer = re.sub(r"role=['\"][^'\"]*['\"]\s*", "", answer)
                        answer = re.sub(r"thinking=None\s*", "", answer)
                        answer = re.sub(r"images=None\s*", "", answer)
                        answer = re.sub(r"tool_name=None\s*", "", answer)
                        answer = re.sub(r"tool_calls=None\s*", "", answer)
                        answer = answer.strip()
                    
                    logger.info(f"Answer extracted (length: {len(answer)})")
                    
                    return {"output": answer}
                except Exception as e:
                    import traceback
                    logger.error(f"Error in retrieval agent: {str(e)}")
                    logger.error(f"Traceback: {traceback.format_exc()}")
                    return {"output": f"Error: {str(e)}"}
        
        return SimpleAgent()
    
    def get_tool(self):
        """Get the retrieval tool for use by other agents."""
        return self.tool
    
    async def process_query(self, query: str) -> Dict[str, Any]:
        """
        Process a retrieval query.
        
        Args:
            query: User's query
        
        Returns:
            Response dictionary with answer and metadata
        """
        try:
            response = await self.agent.ainvoke({"input": query})
            
            # Extract answer from response
            answer = ""
            if isinstance(response, dict):
                answer = response.get("output", "")
                if not answer:
                    messages = response.get("messages", [])
                    if messages:
                        last_msg = messages[-1]
                        if isinstance(last_msg, dict):
                            answer = last_msg.get("content", "")
                        else:
                            answer = str(last_msg)
            else:
                answer = str(response)
            
            if not answer:
                answer = "I received an empty response. Please try again."
            
            return {
                "answer": answer,
                "metadata": {
                    "agent": "retrieval",
                    "model": getattr(self.llm, 'model', 'unknown') if hasattr(self.llm, 'model') else "unknown"
                }
            }
        except Exception as e:
            return {
                "answer": f"I encountered an error: {str(e)}",
                "metadata": {
                    "agent": "retrieval",
                    "error": str(e)
                }
            }

